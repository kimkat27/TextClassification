{"cells":[{"cell_type":"markdown","source":["Data Cleaning"],"metadata":{"id":"t5sHEBn0C9ks"},"id":"t5sHEBn0C9ks"},{"cell_type":"code","source":["#Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"28r4NN_Q_M90","executionInfo":{"status":"ok","timestamp":1739244624941,"user_tz":-480,"elapsed":11359,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"30359299-2555-4c2a-e5f9-c6f955355e5c"},"id":"28r4NN_Q_M90","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#Import necessary libraries\n","import os\n","import pandas as pd\n","import re\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import joblib"],"metadata":{"id":"suWes3jR_niL"},"id":"suWes3jR_niL","execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Define the path to the folder containing your text files\n","label_path = '/content/drive/MyDrive/TextClassification/Dataset/EmoEvaluation'\n","\n","# Function to remove unwanted lines from a file\n","def remove_unwanted_lines(file_path):\n","    with open(file_path, 'r') as file:\n","        lines = file.readlines()\n","\n","    # Filter lines that don't start with \"C-E\" or \"A-E\"\n","    cleaned_lines = [line for line in lines if not (line.startswith(\"C-E\") or line.startswith(\"A-E\"))]\n","\n","    # Write the cleaned lines back to the file\n","    with open(file_path, 'w') as file:\n","        file.writelines(cleaned_lines)\n","\n","# List all .txt files in the folder\n","label_files = [f for f in os.listdir(label_path) if f.endswith('.txt')]\n","\n","if label_files:\n","    for file in label_files:\n","        file_path = os.path.join(label_path, file)\n","\n","        # Remove unwanted lines from the file\n","        remove_unwanted_lines(file_path)\n","        print(f\"Processed {file}\")\n","else:\n","    print(\"No .txt files found in the labels directory.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"LzG67kMnVjM-","executionInfo":{"status":"ok","timestamp":1739249919232,"user_tz":-480,"elapsed":567,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"9f3d2d2d-4890-48bc-8f60-4920472b83cd"},"id":"LzG67kMnVjM-","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processed Ses05F_script01_2.txt\n","Processed Ses05F_impro02.txt\n","Processed Ses05F_impro05.txt\n","Processed Ses05M_impro03.txt\n","Processed Ses05M_script02_1.txt\n","Processed Ses05F_script03_2.txt\n","Processed Ses05M_script01_3.txt\n","Processed Ses05M_impro01.txt\n","Processed Ses05F_impro07.txt\n","Processed Ses05F_impro06.txt\n","Processed Ses05M_script02_2.txt\n","Processed Ses05M_impro05.txt\n","Processed Ses05F_impro08.txt\n","Processed Ses05M_script01_1b.txt\n","Processed Ses05M_impro04.txt\n","Processed Ses05F_script02_1.txt\n","Processed Ses05F_script02_2.txt\n","Processed Ses05M_impro06.txt\n","Processed Ses05M_script03_1.txt\n","Processed Ses05M_impro07.txt\n","Processed Ses05F_script01_3.txt\n","Processed Ses05F_script03_1.txt\n","Processed Ses05M_script01_1.txt\n","Processed Ses05F_impro04.txt\n","Processed Ses05M_script03_2.txt\n","Processed Ses05F_impro03.txt\n","Processed Ses05M_impro08.txt\n","Processed Ses05M_script01_2.txt\n","Processed Ses05M_impro02.txt\n","Processed Ses05F_script01_1.txt\n","Processed Ses05F_impro01.txt\n"]}]},{"cell_type":"code","source":["# Dataset paths\n","label_path = \"/content/drive/MyDrive/TextClassification/Dataset/EmoEvaluation\""],"metadata":{"id":"2gK8bP4sGZ04"},"id":"2gK8bP4sGZ04","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create output directories inside dataset path\n","converted_labels_path = \"/content/drive/MyDrive/TextClassification/Dataset/converted_labels\"\n","\n","# Create the directories if they don't already exist\n","os.makedirs(converted_labels_path, exist_ok=True)"],"metadata":{"id":"MrngoGJgGguT"},"id":"MrngoGJgGguT","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create output folder if it doesn't exist\n","if not os.path.exists(converted_labels_path):\n","    os.makedirs(converted_labels_path)\n","\n","# Function to process each text file and convert it to CSV\n","def convert_txt_to_csv(file_path, output_file_path):\n","    with open(file_path, 'r') as file:\n","        lines = file.readlines()\n","\n","    # Prepare a list to hold the rows of the DataFrame\n","    data = []\n","\n","    # Process the lines to extract meaningful data\n","    for line in lines:\n","        # Skip unwanted lines starting with \"C-E\" or \"A-E\"\n","        if line.startswith(\"C-E\") or line.startswith(\"A-E\"):\n","            continue\n","\n","        # Split by tabs and spaces to separate the columns\n","        split_line = line.strip().split('\\t')\n","\n","        if len(split_line) == 4:\n","            # If there are 4 items, we treat it as a valid row (e.g., [START_TIME - END_TIME], TURN_NAME, EMOTION, [V, A, D])\n","            data.append(split_line)\n","\n","    # Create a DataFrame from the data\n","    df = pd.DataFrame(data, columns=[\"% [START_TIME - END_TIME]\", \"TURN_NAME\", \"EMOTION\", \"[V, A, D]\"])\n","\n","    # Save the DataFrame as a CSV file\n","    df.to_csv(output_file_path, index=False)\n","\n","# List all .txt files in the folder\n","label_files = [f for f in os.listdir(label_path) if f.endswith('.txt')]\n","\n","if label_files:\n","    for file in label_files:\n","        file_path = os.path.join(label_path, file)\n","        output_file_path = os.path.join(converted_labels_path, file.replace('.txt', '.csv'))\n","\n","        # Convert the .txt file to .csv\n","        convert_txt_to_csv(file_path, output_file_path)\n","        print(f\"Converted {file} to CSV.\")\n","else:\n","    print(\"No .txt files found in the labels directory.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"GESbAHn2DM-4","executionInfo":{"status":"ok","timestamp":1739250398991,"user_tz":-480,"elapsed":637,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"07daaeea-c177-4d8f-c316-20d27bb42a73"},"id":"GESbAHn2DM-4","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Converted Ses05F_script01_2.txt to CSV.\n","Converted Ses05F_impro02.txt to CSV.\n","Converted Ses05F_impro05.txt to CSV.\n","Converted Ses05M_impro03.txt to CSV.\n","Converted Ses05M_script02_1.txt to CSV.\n","Converted Ses05F_script03_2.txt to CSV.\n","Converted Ses05M_script01_3.txt to CSV.\n","Converted Ses05M_impro01.txt to CSV.\n","Converted Ses05F_impro07.txt to CSV.\n","Converted Ses05F_impro06.txt to CSV.\n","Converted Ses05M_script02_2.txt to CSV.\n","Converted Ses05M_impro05.txt to CSV.\n","Converted Ses05F_impro08.txt to CSV.\n","Converted Ses05M_script01_1b.txt to CSV.\n","Converted Ses05M_impro04.txt to CSV.\n","Converted Ses05F_script02_1.txt to CSV.\n","Converted Ses05F_script02_2.txt to CSV.\n","Converted Ses05M_impro06.txt to CSV.\n","Converted Ses05M_script03_1.txt to CSV.\n","Converted Ses05M_impro07.txt to CSV.\n","Converted Ses05F_script01_3.txt to CSV.\n","Converted Ses05F_script03_1.txt to CSV.\n","Converted Ses05M_script01_1.txt to CSV.\n","Converted Ses05F_impro04.txt to CSV.\n","Converted Ses05M_script03_2.txt to CSV.\n","Converted Ses05F_impro03.txt to CSV.\n","Converted Ses05M_impro08.txt to CSV.\n","Converted Ses05M_script01_2.txt to CSV.\n","Converted Ses05M_impro02.txt to CSV.\n","Converted Ses05F_script01_1.txt to CSV.\n","Converted Ses05F_impro01.txt to CSV.\n"]}]},{"cell_type":"code","source":["# Specify the folder path where your .txt files are located\n","transcriptions_path = '/content/drive/MyDrive/TextClassification/Dataset/transcriptions'\n","\n","# Specify the path for the new folder where you want to save the .csv files\n","output_folder = '/content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions'\n","\n","# Ensure the new folder exists\n","os.makedirs(output_folder, exist_ok=True)\n","\n","# Column names to add\n","column_names = ['TURN_NAME', '% [START_TIME - END_TIME]', 'TEXT']\n","\n","# Iterate through all files in the folder\n","for filename in os.listdir(transcriptions_path):\n","    file_path = os.path.join(transcriptions_path, filename)\n","\n","    # Only process .txt files\n","    if filename.endswith('.txt'):\n","        try:\n","            # Open the file and process each line\n","            with open(file_path, 'r') as file:\n","                lines = file.readlines()\n","\n","            # Prepare lists to hold data for the DataFrame\n","            turn_names = []\n","            timestamps = []\n","            texts = []\n","\n","            # Process each line in the file\n","            for line in lines:\n","                # Use regex to extract speaker, timestamp, and text\n","                match = re.match(r'([^\\[]+)\\s+\\[([^\\]]+)\\]:\\s*(.*)', line.strip())\n","                if match:\n","                    turn_name = match.group(1).strip()\n","                    timestamp = match.group(2).strip()\n","                    text = match.group(3).strip()\n","\n","                    turn_names.append(turn_name)\n","                    timestamps.append(timestamp)\n","                    texts.append(text)\n","\n","            # Create a DataFrame\n","            df = pd.DataFrame({\n","                'TURN_NAME': turn_names,\n","                '% [START_TIME - END_TIME]': timestamps,\n","                'TEXT': texts\n","            })\n","\n","            # Create new file path for saving as .csv in the new folder\n","            csv_file_path = os.path.join(output_folder, filename.replace('.txt', '.csv'))\n","\n","            # Save the DataFrame as a .csv file in the new folder\n","            df.to_csv(csv_file_path, index=False)\n","\n","            print(f\"File {filename} converted to CSV and saved as {csv_file_path}.\")\n","\n","        except Exception as e:\n","            print(f\"Error processing {filename}: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"498FNgl9It5U","executionInfo":{"status":"ok","timestamp":1739252008990,"user_tz":-480,"elapsed":615,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"4b069e61-4e61-45c7-e2b6-806fe104bb80"},"id":"498FNgl9It5U","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["File Ses05F_impro07.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_impro07.csv.\n","File Ses05M_script03_1.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_script03_1.csv.\n","File Ses05F_impro03.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_impro03.csv.\n","File Ses05F_impro08.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_impro08.csv.\n","File Ses05M_script01_2.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_script01_2.csv.\n","File Ses05M_impro03.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_impro03.csv.\n","File Ses05F_impro02.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_impro02.csv.\n","File Ses05M_script02_1.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_script02_1.csv.\n","File Ses05M_impro04.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_impro04.csv.\n","File Ses05M_script01_3.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_script01_3.csv.\n","File Ses05F_script01_1.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_script01_1.csv.\n","File Ses05F_script01_3.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_script01_3.csv.\n","File Ses05M_script02_2.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_script02_2.csv.\n","File Ses05M_script01_1b.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_script01_1b.csv.\n","File Ses05M_script03_2.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_script03_2.csv.\n","File Ses05F_script03_2.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_script03_2.csv.\n","File Ses05F_script02_1.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_script02_1.csv.\n","File Ses05M_impro01.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_impro01.csv.\n","File Ses05F_script01_2.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_script01_2.csv.\n","File Ses05M_impro07.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_impro07.csv.\n","File Ses05F_script02_2.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_script02_2.csv.\n","File Ses05M_impro06.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_impro06.csv.\n","File Ses05M_impro05.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_impro05.csv.\n","File Ses05M_impro08.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_impro08.csv.\n","File Ses05F_impro06.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_impro06.csv.\n","File Ses05M_impro02.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_impro02.csv.\n","File Ses05F_impro04.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_impro04.csv.\n","File Ses05F_script03_1.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_script03_1.csv.\n","File Ses05F_impro05.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_impro05.csv.\n","File Ses05M_script01_1.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_script01_1.csv.\n","File Ses05F_impro01.txt converted to CSV and saved as /content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05F_impro01.csv.\n"]}]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","\n","# Path to the folder containing the files\n","folder_path = '/content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions'\n","\n","# Loop through all files in the folder\n","for filename in os.listdir(folder_path):\n","    file_path = os.path.join(folder_path, filename)\n","\n","    if filename.endswith('.csv'):  # Modify for other file formats like .xlsx if needed\n","        # Read the CSV file into a DataFrame\n","        df = pd.read_csv(file_path)\n","\n","        # Find columns with the pattern % [START_TIME - END_TIME]\n","        columns_to_drop = [col for col in df.columns if '%' in col and '[' in col and ']' in col]\n","\n","        # Drop the columns\n","        df.drop(columns=columns_to_drop, inplace=True)\n","\n","        # Save the updated file back\n","        df.to_csv(file_path, index=False)\n","        print(f\"Updated {filename} - Removed columns: {columns_to_drop}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"MGtdh8MxZmNF","executionInfo":{"status":"ok","timestamp":1739252382147,"user_tz":-480,"elapsed":629,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"86e19134-e243-4f97-d244-6bd390d9f23e"},"id":"MGtdh8MxZmNF","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Updated Ses05F_impro07.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_impro03.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_script02_1.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_impro02.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_script01_3.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_script01_1.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_impro03.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_script01_2.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_impro04.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_impro08.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_script03_1.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_script01_3.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_script01_1b.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_script02_2.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_script02_1.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_script03_2.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_script03_2.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_impro01.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_script01_2.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_script02_2.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_impro07.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_impro06.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_impro05.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_impro08.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_impro06.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_impro02.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_impro04.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_script03_1.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_impro01.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05M_script01_1.csv - Removed columns: ['% [START_TIME - END_TIME]']\n","Updated Ses05F_impro05.csv - Removed columns: ['% [START_TIME - END_TIME]']\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import os\n","\n","# Define the paths to your folders\n","labels_folder = '/content/drive/MyDrive/TextClassification/Dataset/converted_labels'\n","transcriptions_folder = '/content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions'\n","\n","# List all files in the folders (assuming the files have a .csv extension)\n","labels_files = [f for f in os.listdir(labels_folder) if f.endswith('.csv')]\n","transcriptions_files = [f for f in os.listdir(transcriptions_folder) if f.endswith('.csv')]\n","\n","# Check column names for each file in the labels folder\n","for label_file in labels_files:\n","    label_path = os.path.join(labels_folder, label_file)\n","    labels_df = pd.read_csv(label_path, sep=\"\\t\")\n","    print(f\"Columns in label file {label_file}: {labels_df.columns.tolist()}\")\n","\n","# Check column names for each file in the transcriptions folder\n","for transcription_file in transcriptions_files:\n","    transcription_path = os.path.join(transcriptions_folder, transcription_file)\n","    transcriptions_df = pd.read_csv(transcription_path, sep=\",\")\n","    print(f\"Columns in transcription file {transcription_file}: {transcriptions_df.columns.tolist()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"UU2YlUgFr3-z","executionInfo":{"status":"ok","timestamp":1739255349033,"user_tz":-480,"elapsed":424,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"2ce4ebdf-4181-4d31-826f-a70b23a3971d"},"id":"UU2YlUgFr3-z","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Columns in label file Ses05F_script01_2.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_impro03.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_script03_2.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_impro07.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_impro01.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_script02_2.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_impro06.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_script01_3.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_impro02.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_script02_1.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_impro05.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_impro08.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_impro05.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_impro01.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_script02_1.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_script01_1b.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_impro04.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_script02_2.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_impro06.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_impro07.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_script03_1.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_script01_3.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_script03_1.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_script01_1.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_impro04.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_script03_2.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_impro03.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_impro08.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_script01_2.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05M_impro02.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in label file Ses05F_script01_1.csv: ['% [START_TIME - END_TIME],TURN_NAME,EMOTION,\"[V, A, D]\"']\n","Columns in transcription file Ses05F_impro07.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_impro03.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_script02_1.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_impro02.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_script01_3.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_script01_1.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_impro03.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_script01_2.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_impro04.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_impro08.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_script03_1.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_script01_3.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_script01_1b.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_script02_2.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_script02_1.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_script03_2.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_script03_2.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_impro01.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_script01_2.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_script02_2.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_impro07.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_impro06.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_impro05.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_impro08.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_impro06.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_impro02.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_impro04.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_script03_1.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_impro01.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05M_script01_1.csv: ['TURN_NAME', 'TEXT']\n","Columns in transcription file Ses05F_impro05.csv: ['TURN_NAME', 'TEXT']\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import os\n","\n","# Paths to your input files\n","file1_path = '/content/drive/MyDrive/TextClassification/Dataset/converted_labels/Ses05M_script03_2.csv'\n","file2_path = '/content/drive/MyDrive/TextClassification/Dataset/converted_transcriptions/Ses05M_script03_2.csv'\n","\n","# Read the CSV files into pandas DataFrames\n","df1 = pd.read_csv(file1_path)\n","df2 = pd.read_csv(file2_path)\n","\n","# Merge the files based on the \"TURN_NAME\" column\n","merged_df = pd.merge(df1, df2, on=\"TURN_NAME\", how=\"outer\")  # Use 'outer' to keep all rows\n","\n","# Create a new folder to save the merged file\n","output_folder = '/content/drive/MyDrive/TextClassification/Dataset/merged_data'\n","os.makedirs(output_folder, exist_ok=True)\n","\n","# Get the file name from the original file path (keeping the name of the first file as an example)\n","file_name = os.path.basename(file1_path)\n","\n","# Save the merged file in the new folder with the same name\n","output_path = os.path.join(output_folder, file_name)\n","merged_df.to_csv(output_path, index=False)\n","\n","print(f\"Merged file saved as {output_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x7cfojvWrb2K","executionInfo":{"status":"ok","timestamp":1739369515095,"user_tz":-480,"elapsed":1121,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"8e165940-8813-490a-dc4e-ded2332ae55a"},"id":"x7cfojvWrb2K","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Merged file saved as /content/drive/MyDrive/TextClassification/Dataset/merged_data/Ses05M_script03_2.csv\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Path to your CSV file\n","file_path = '/content/drive/MyDrive/TextClassification/Dataset/merged_data/Ses05M_script03_2.csv'\n","\n","# Read the CSV file into a DataFrame\n","df = pd.read_csv(file_path)\n","\n","# 1. Check if there are any missing values in any column\n","missing_values = df[df.isna().any(axis=1)]  # Rows with missing values in any column\n","if not missing_values.empty:\n","    print(\"Rows with missing values:\")\n","    print(missing_values)\n","else:\n","    print(\"No missing values in any column.\")\n","\n","# 2. Check for empty rows (rows where all columns are NaN)\n","empty_rows = df[df.isna().all(axis=1)]\n","if not empty_rows.empty:\n","    print(\"\\nEmpty rows found (rows where all values are NaN):\")\n","    print(empty_rows)\n","else:\n","    print(\"\\nNo empty rows found.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X1U6xF5-SYOe","executionInfo":{"status":"ok","timestamp":1739369530354,"user_tz":-480,"elapsed":380,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"7118a020-7975-4472-e710-ed3d5a6bda23"},"id":"X1U6xF5-SYOe","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["No missing values in any column.\n","\n","No empty rows found.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Path to the merged file\n","file_path = '/content/drive/MyDrive/TextClassification/Dataset/merged_data/Ses05M_script02_2.csv'\n","\n","# Read the CSV file into a DataFrame\n","df = pd.read_csv(file_path)\n","\n","# Check if the specific row 'Ses05F_impro01_FXX0' has missing EMOTION and delete it if so\n","df = df[~((df['TURN_NAME'] == 'Ses05M_script02_2_FXX0') & df['EMOTION'].isna())]\n","\n","# Save the modified DataFrame back to the same CSV file\n","df.to_csv(file_path, index=False)\n","\n","print(f\"Updated file saved as {file_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UY1ynamEMa1n","executionInfo":{"status":"ok","timestamp":1739369383580,"user_tz":-480,"elapsed":402,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"896d9456-fba2-4f1a-f781-ddfb8ab70749"},"id":"UY1ynamEMa1n","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Updated file saved as /content/drive/MyDrive/TextClassification/Dataset/merged_data/Ses05M_script02_2.csv\n"]}]},{"cell_type":"markdown","source":["################################################################################"],"metadata":{"id":"WLbnjvKyDFU8"},"id":"WLbnjvKyDFU8"},{"cell_type":"markdown","source":["Start of Data pre-processing"],"metadata":{"id":"KAfg_tXlC2kh"},"id":"KAfg_tXlC2kh"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wAqN1td7-bms","executionInfo":{"status":"ok","timestamp":1739363467091,"user_tz":-480,"elapsed":55403,"user":{"displayName":"KIMBERLY TRIPULCA","userId":"06264182523271799652"}},"outputId":"2ab4aa0e-9181-41cf-b1f6-e3ca7779d5d7"},"id":"wAqN1td7-bms","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"J9WgkEMDCAHf"},"id":"J9WgkEMDCAHf","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}